# æ•°æ®é›†ç®¡ç†

æœ¬ç›®å½•ç”¨äºç®¡ç†æ‰€æœ‰ç”¨äºåŸºå‡†æµ‹è¯•çš„æ•°æ®é›†ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
datasets/
â”œâ”€â”€ raw/                    # åŸå§‹ä¸‹è½½çš„æ•°æ®
â”‚   â”œâ”€â”€ wikipedia-zh/
â”‚   â”œâ”€â”€ clue-corpus/
â”‚   â””â”€â”€ dureader/
â”‚
â”œâ”€â”€ processed/              # è½¬æ¢åçš„ TSV æ ¼å¼
â”‚   â”œâ”€â”€ wikipedia-zh.tsv
â”‚   â”œâ”€â”€ clue-corpus.tsv
â”‚   â””â”€â”€ test-small.tsv
â”‚
â”œâ”€â”€ scripts/                # æ•°æ®å¤„ç†è„šæœ¬
â”‚   â”œâ”€â”€ convert_to_tsv.py
â”‚   â”œâ”€â”€ validate_tsv.py
â”‚   â””â”€â”€ prepare_dataset.sh
â”‚
â””â”€â”€ README.md              # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®é›†

#### æ–¹å¼ Aï¼šä» Hugging Face ç›´æ¥ä¸‹è½½å¹¶è½¬æ¢

```bash
cd ~/VectorDB-Benchmark/datasets/scripts

# ä¸‹è½½ Wikipedia ä¸­æ–‡ï¼ˆçº¦130ä¸‡æ¡ï¼‰
python3 convert_to_tsv.py \
  --format huggingface \
  "wikipedia" \
  ../processed/wikipedia-zh.tsv \
  --text-field text \
  --max-samples 1500000

# ä¸‹è½½ CLUECorpus2020ï¼ˆçº¦1400ä¸‡æ¡ï¼Œå–300ä¸‡ï¼‰
python3 convert_to_tsv.py \
  --format huggingface \
  "CLUEbenchmark/CLUECorpus2020" \
  ../processed/clue-corpus.tsv \
  --text-field content \
  --max-samples 3000000
```

#### æ–¹å¼ Bï¼šè½¬æ¢æœ¬åœ°æ–‡ä»¶

```bash
# JSON æ ¼å¼
python3 convert_to_tsv.py \
  --format json \
  ../raw/my-dataset/data.json \
  ../processed/my-dataset.tsv \
  --text-field text

# Parquet æ ¼å¼
python3 convert_to_tsv.py \
  --format parquet \
  ../raw/my-dataset/data.parquet \
  ../processed/my-dataset.tsv \
  --text-field text
```

### 2. æ ¡éªŒæ•°æ®é›†

```bash
cd ~/VectorDB-Benchmark/datasets/scripts

# æ ¡éªŒæ ¼å¼
python3 validate_tsv.py ../processed/wikipedia-zh.tsv

# æ ¡éªŒæ›´å¤šè¡Œï¼ˆé»˜è®¤åªæ£€æŸ¥å‰1000è¡Œï¼‰
python3 validate_tsv.py ../processed/wikipedia-zh.tsv --check-lines 10000
```

### 3. åˆ‡æ¢æµ‹è¯•æ•°æ®é›†

```bash
cd ~/VectorDB-Benchmark/datasets/scripts

# æ–¹å¼1ï¼šä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰
chmod +x prepare_dataset.sh

# åˆ—å‡ºå¯ç”¨æ•°æ®é›†
./prepare_dataset.sh

# åˆ‡æ¢åˆ° Wikipedia ä¸­æ–‡æ•°æ®é›†
./prepare_dataset.sh wikipedia-zh.tsv

# åˆ‡æ¢åˆ° CLUE æ•°æ®é›†
./prepare_dataset.sh clue-corpus.tsv

# æ–¹å¼2ï¼šæ‰‹åŠ¨åˆ›å»ºè½¯é“¾æ¥
ln -sf ~/VectorDB-Benchmark/datasets/processed/wikipedia-zh.tsv \
       ~/VectorDB-Benchmark/phase1_embedding/data/ms_marco/collection.tsv
```

### 4. è¿è¡Œæµ‹è¯•

```bash
cd ~/VectorDB-Benchmark/phase1_embedding
python run_phase1.py --config ../config/phase1_config.yaml
```

## ğŸ“‹ æ•°æ®é›†è¦æ±‚

### æ ¼å¼è¦æ±‚

- **æ–‡ä»¶æ ¼å¼**: TSV (Tab-Separated Values)
- **ç¼–ç **: UTF-8
- **æ¯è¡Œæ ¼å¼**: `<æ–‡æ¡£ID>\t<æ–‡æ¡£å†…å®¹>`
- **æ–‡æ¡£ID**: å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆæ•°å­—æˆ–å­—ç¬¦ä¸²ï¼‰
- **æ–‡æ¡£å†…å®¹**: çº¯æ–‡æœ¬ï¼Œä¸åŒ…å«æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦

### å†…å®¹è¦æ±‚

- **æ–‡æœ¬é•¿åº¦**: å»ºè®® 10-512 å­—ç¬¦ï¼ˆå¯åœ¨è½¬æ¢æ—¶æŒ‡å®šï¼‰
- **æ•°æ®é‡**: æ ¹æ®æµ‹è¯•éœ€æ±‚ï¼Œå»ºè®® 10ä¸‡-500ä¸‡æ¡
- **è¯­è¨€**: ä¸­æ–‡æˆ–è‹±æ–‡
- **è´¨é‡**: çœŸå®æ–‡æœ¬ï¼Œé¿å…å¤§é‡é‡å¤

### ç¤ºä¾‹

```tsv
0	äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œéœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚
1	æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ è€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚
2	æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„æ¨¡å¼è¯†åˆ«ä»»åŠ¡ã€‚
```

## ğŸ”„ æ•°æ®é›†ç®¡ç†å·¥ä½œæµ

### å®Œæ•´æµç¨‹

```bash
# 1. ä¸‹è½½åŸå§‹æ•°æ®åˆ° raw/
cd ~/VectorDB-Benchmark/datasets/raw
# ... ä¸‹è½½æ•°æ® ...

# 2. è½¬æ¢ä¸º TSV æ ¼å¼
cd ~/VectorDB-Benchmark/datasets/scripts
python3 convert_to_tsv.py \
  --format json \
  ../raw/my-dataset/data.json \
  ../processed/my-dataset.tsv

# 3. æ ¡éªŒæ ¼å¼
python3 validate_tsv.py ../processed/my-dataset.tsv

# 4. å‡†å¤‡æµ‹è¯•
./prepare_dataset.sh my-dataset.tsv

# 5. è¿è¡Œæµ‹è¯•
cd ~/VectorDB-Benchmark/phase1_embedding
python run_phase1.py --config ../config/phase1_config.yaml

# 6. åˆ‡æ¢æ•°æ®é›†é‡å¤æµ‹è¯•
cd ~/VectorDB-Benchmark/datasets/scripts
./prepare_dataset.sh another-dataset.tsv
cd ~/VectorDB-Benchmark/phase1_embedding
python run_phase1.py --config ../config/phase1_config.yaml
```

## ğŸ“Š æ¨èæ•°æ®é›†

### ä¸­æ–‡æ•°æ®é›†

| æ•°æ®é›† | è§„æ¨¡ | æ¥æº | æ¨èåº¦ | ä¸‹è½½æ–¹å¼ |
|--------|------|------|--------|----------|
| Wikipedia-zh | 130ä¸‡ | ç»´åŸºç™¾ç§‘ | â­â­â­â­â­ | Hugging Face |
| CLUECorpus2020 | 1400ä¸‡+ | æ–°é—»/ç™¾ç§‘ | â­â­â­â­â­ | Hugging Face |
| DuReader | 90ä¸‡ | ç™¾åº¦æœç´¢ | â­â­â­â­ | Hugging Face |

### è‹±æ–‡æ•°æ®é›†

| æ•°æ®é›† | è§„æ¨¡ | æ¥æº | æ¨èåº¦ | ä¸‹è½½æ–¹å¼ |
|--------|------|------|--------|----------|
| MS MARCO | 880ä¸‡ | å¾®è½¯æœç´¢ | â­â­â­â­â­ | å®˜æ–¹/Hugging Face |
| Wikipedia-en | 600ä¸‡+ | ç»´åŸºç™¾ç§‘ | â­â­â­â­â­ | Hugging Face |

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### åˆ›å»ºæµ‹è¯•å­é›†

```bash
# ä»å¤§æ•°æ®é›†åˆ›å»ºå°æµ‹è¯•é›†
head -n 100000 ../processed/clue-corpus.tsv > ../processed/test-100k.tsv

# æˆ–ä½¿ç”¨è½¬æ¢è„šæœ¬é™åˆ¶è¡Œæ•°
python3 convert_to_tsv.py \
  --format huggingface \
  "CLUEbenchmark/CLUECorpus2020" \
  ../processed/test-small.tsv \
  --max-samples 100000
```

### åˆå¹¶å¤šä¸ªæ•°æ®é›†

```bash
# åˆå¹¶å¤šä¸ªæ•°æ®é›†
cat ../processed/wikipedia-zh.tsv \
    ../processed/dureader.tsv \
    > ../processed/combined.tsv

# é‡æ–°ç¼–å·ID
awk -F'\t' '{print NR-1 "\t" $2}' ../processed/combined.tsv \
    > ../processed/combined-reindex.tsv
```

### æ•°æ®é›†ç»Ÿè®¡

```bash
# ç»Ÿè®¡è¡Œæ•°
wc -l ../processed/*.tsv

# ç»Ÿè®¡æ–‡ä»¶å¤§å°
du -h ../processed/*.tsv

# æŠ½æ ·æŸ¥çœ‹
head -n 10 ../processed/wikipedia-zh.tsv
tail -n 10 ../processed/wikipedia-zh.tsv
```

## ğŸ” æ•…éšœæ’æŸ¥

### è½¬æ¢å¤±è´¥

```bash
# æ£€æŸ¥ Python ä¾èµ–
pip install datasets pandas pyarrow tqdm

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ£€æŸ¥å†…å­˜
free -h
```

### æ ¡éªŒå¤±è´¥

```bash
# æ£€æŸ¥æ–‡ä»¶ç¼–ç 
file ../processed/my-dataset.tsv

# æ£€æŸ¥æ–‡ä»¶æ ¼å¼
head -n 5 ../processed/my-dataset.tsv | cat -A

# æ‰‹åŠ¨ä¿®å¤ï¼ˆå»é™¤æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦ï¼‰
sed 's/\t/ /g; s/\n/ /g' input.tsv > output.tsv
```

### è½¯é“¾æ¥é—®é¢˜

```bash
# æ£€æŸ¥è½¯é“¾æ¥
ls -l ~/VectorDB-Benchmark/phase1_embedding/data/ms_marco/collection.tsv

# åˆ é™¤æŸåçš„è½¯é“¾æ¥
rm ~/VectorDB-Benchmark/phase1_embedding/data/ms_marco/collection.tsv

# é‡æ–°åˆ›å»º
./prepare_dataset.sh wikipedia-zh.tsv
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ç£ç›˜ç©ºé—´**: ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´å­˜å‚¨åŸå§‹æ•°æ®å’Œè½¬æ¢åçš„ TSV æ–‡ä»¶
2. **å¤‡ä»½**: é‡è¦æ•°æ®é›†å»ºè®®å¤‡ä»½åˆ°å¤šä¸ªä½ç½®
3. **ç‰ˆæœ¬ç®¡ç†**: è®°å½•æ•°æ®é›†ç‰ˆæœ¬å’Œæ¥æºï¼Œæ–¹ä¾¿å¤ç°ç»“æœ
4. **æ¸…ç†**: å®šæœŸæ¸…ç†ä¸éœ€è¦çš„æ•°æ®é›†å’Œå¤‡ä»½æ–‡ä»¶

## ğŸ†˜ è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹è„šæœ¬å¸®åŠ©
python3 convert_to_tsv.py --help
python3 validate_tsv.py --help
./prepare_dataset.sh
```
