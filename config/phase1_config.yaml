# 阶段一：向量生成性能测试配置

# Xinference 服务配置
xinference:
  host: "192.168.1.51"
  port: 9997
  timeout: 300

# 测试模型列表（按顺序串行测试）
# 注意：model_name 应该与 Xinference 中的实际模型 ID 匹配
# 可以通过 curl http://192.168.1.51:9997/v1/models 查看实际可用的模型ID
models:
  - name: "bge-m3"
    model_name: "bge-m3"  # Xinference中的实际ID
    dimensions: 1024
    max_tokens: 8192
    batch_sizes: [64, 128, 256, 512]  # 优化：增大batch size范围
    
  - name: "qwen3-0.6b"
    model_name: "Qwen3-Embedding-0.6B"  # Xinference中的实际ID
    dimensions: 1024
    max_tokens: 32768
    batch_sizes: [128, 256, 512, 1024]  # 优化：小模型用更大batch
    
  - name: "qwen3-4b"
    model_name: "Qwen3-Embedding-4B"  # Xinference中的实际ID
    dimensions: 2560
    max_tokens: 32768
    batch_sizes: [64, 128, 256]  # 优化：适度增大batch size
    
  - name: "qwen3-8b"
    model_name: "Qwen3-Embedding-8B"  # Xinference中的实际ID
    dimensions: 4096
    max_tokens: 32768
    batch_sizes: [32, 64, 128]  # 优化：增大batch size

# 数据集配置
dataset:
  name: "benchmark_dataset"  # 数据集名称（仅用于日志）
  path: "data/dataset"  # 数据集路径
  sample_size: 3000000  # 目标采样数量（实际使用 min(sample_size, 文件行数)）
  seed: 42  # 随机种子
  max_length: 512  # 最大文本长度
  min_length: 10  # 最小文本长度

# 向量缓存配置
vector_cache:
  format: "hdf5"
  output_dir: "results/cache"
  compression: "gzip"
  compression_level: 4
  chunk_size: 10000

# 报告生成配置
report:
  output_dir: "results"
  format: "html"
  include_plots: true
  plot_style: "plotly"
  
  # 推算配置
  extrapolate:
    scales: [5000000, 10000000, 50000000, 100000000]
    
# 日志配置
logging:
  level: "WARNING"  # 减少日志刷屏
  log_dir: "logs"
  log_file: "phase1.log"

# 性能配置（极限性能，榨干GPU）
performance:
  concurrent_requests: 16  # 并发请求数
  max_batch_size: 2048  # 最大batch size
  auto_batch_tuning: true  # 自动调优
  connection_pool_size: 32  # HTTP连接池
  pause_between_models: 5  # 模型间暂停秒数

# 分批测试配置（用于显存不足时）
# 如果定义了批次，可以通过 --batch 参数指定要运行的批次
# 例如：python run_phase1.py --config ../config/phase1_config.yaml --batch 1
batch_groups:
  # 第一批：较小的模型（显存占用较小）
  - batch_id: 1
    batch_name: "small_models"
    model_names:
      - "bge-m3"
      - "qwen3-0.6b"
  
  # 第二批：较大的模型（显存占用较大）
  - batch_id: 2
    batch_name: "large_models"
    model_names:
      - "qwen3-4b"
      - "qwen3-8b"
